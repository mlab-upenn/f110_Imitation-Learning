#!/usr/bin/env python
from __future__ import print_function

import roslib, os, sys, rospy, cv2, math, time, torch
from std_msgs.msg import String, Header, ColorRGBA
from sensor_msgs.msg import Image
from cv_bridge import CvBridge, CvBridgeError
from visualization_msgs.msg import Marker, MarkerArray
from geometry_msgs.msg import Pose, Point, Quaternion, Vector3, PointStamped
from ackermann_msgs.msg import AckermannDriveStamped, AckermannDrive
from models import NVIDIA_ConvNet
from data_utils import Data_Utils
import numpy as np
device = torch.device('cuda' if torch.cuda.is_available else 'cpu') 

class NN_Steer(object):
    """
    ROS Class that allows steering a F110 Car using commands generated by a Pytorch Neural Network
    """
    def __init__(self, model_type='train', idx=-1):

        #get the right model crap
        self.log_path = json.load(open("params.txt"))["log_path"]        
        log_folders = os.listdir(self.log_path)
        log_folders.sort()
        foldername = log_folders[idx]
        model_path_name = self.log_path + foldername + '/best_' + model_type + '_model'

        #actually build the model
        self.net = NVIDIA_ConvNet()
        self.net.load_state_dict(torch.load(model_path_name))
        self.net.eval() 

        #SUBSCRIBE TO USB_CAM (SHASHANK)
        self.camera_sub = rospy.Subscriber("", camera_callback)

        self.steer_point_pub = rospy.Publisher("vesc/high_level/ackermann_cmd_mux/input/nav_0", AckermannDriveStamped, queue_size=1)

        torch.set_grad_enabled(False)

        #At what interval should we sample to get a steering angle
        self.interval = 4
        self.framecount = 0
        self.dutils = Data_Utils()

    def camera_callback(self, data):
        if self.framecount % self.interval == 0:
            #GET IMAGE DATA FROM SOMEWHERE AND CONVERT IT INTO CV_IMG (SHASHANK)
            cv_img = None

            #Convert to tensor & run through NN
            ts_frame, _ = self.dutils.preprocess_img(cv_img, label=None, use_for='infer')
            ts_frame = ts_img.to(device)
            ts_frame = ts_frame[None]

            #use net to get pred angle
            angle_pred = self.net(ts_frame)

            #Send msg to car
            vel = 5
            drive_msg = AckermannDriveStamped()
            drive_msg.header.stamp = rospy.Time.now()
            drive_msg.header.frame_id = "odom" #SHASHANK
            drive_msg.drive.steering_angle = angle_pred.item()
            drive_msg.drive.speed = vel * -1.0
            self.steer_point_pub.publis(drive_msg)

        self.framecount += 1