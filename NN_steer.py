#!/usr/bin/env python
from __future__ import print_function

import roslib, os, sys, rospy, cv2, math, time, torch,json
from sensor_msgs.msg import CompressedImage
from std_msgs.msg import String, Header, ColorRGBA
from sensor_msgs.msg import Image
from cv_bridge import CvBridge, CvBridgeError
from visualization_msgs.msg import Marker, MarkerArray
from geometry_msgs.msg import Pose, Point, Quaternion, Vector3, PointStamped
from ackermann_msgs.msg import AckermannDriveStamped, AckermannDrive
from models import NVIDIA_ConvNet
from cv_bridge import CvBridge
from data_utils import Data_Utils
import numpy as np
device = torch.device('cuda' if torch.cuda.is_available else 'cpu') 

class NN_Steer(object):
    """
    ROS Class that allows steering a F110 Car using commands generated by a Pytorch Neural Network
    """
    def __init__(self, model_type='train', idx=-1):

        #get the right model crap
        self.log_path = json.load(open("params.txt"))["log_path"]
        self.params = json.load(open("params.txt"))        
        log_folders = os.listdir(self.log_path)
        log_folders.sort()
        foldername = log_folders[idx]
        model_path_name = self.log_path + foldername + '/best_' + model_type + '_model'
        self.bridge = CvBridge()

        #actually build the model
        self.net = NVIDIA_ConvNet()
        self.net.load_state_dict(torch.load(model_path_name))
        self.net.eval()
        self.net.to(device) 

        #SUBSCRIBE TO USB_CAM (SHASHANK)
        rospy.init_node('Steer_Net', anonymous=True)
        self.camera_sub = rospy.Subscriber(self.params["front_camera"],CompressedImage, self.camera_callback)

        self.steer_point_pub = rospy.Publisher("vesc/high_level/ackermann_cmd_mux/input/nav_0", AckermannDriveStamped, queue_size=1)

        torch.set_grad_enabled(False)

        #At what interval should we sample to get a steering angle
        self.interval = 4
        self.framecount = 0
        self.dutils = Data_Utils()
        print("Setup done")
        rospy.spin()

    def camera_callback(self, data):
        if self.framecount % self.interval == 0:
            #GET IMAGE DATA FROM SOMEWHERE AND CONVERT IT INTO CV_IMG (SHASHANK)
            cv_img = self.bridge.compressed_imgmsg_to_cv2(data)

            #Convert to tensor & run through NN
            ts_frame, _ = self.dutils.preprocess_img(cv_img, label=None, use_for='infer')
            ts_frame = ts_frame.to(device)
            ts_frame = ts_frame[None]

            #use net to get pred angle
            angle_pred = self.net(ts_frame)

            #Send msg to car
            vel = 5
            drive_msg = AckermannDriveStamped()
            drive_msg.header.stamp = rospy.Time.now()
            drive_msg.header.frame_id = "odom" #SHASHANK
            drive_msg.drive.steering_angle = -1.0 * angle_pred.item()*np.pi/180
            drive_msg.drive.speed = vel * -1.0
            self.steer_point_pub.publish(drive_msg)

        self.framecount += 1

if __name__ == "__main__":
    obj=NN_Steer()
