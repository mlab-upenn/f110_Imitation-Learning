#!/usr/bin/env python
from __future__ import print_function
import os, sys, cv2, math, time, torch
import numpy as np
from nnet.models import *
from steps import session
from nnet.Data_Utils import Data_Utils

#ROS Dependencies
import roslib, rospy
import numpy as np
from std_msgs.msg import String
from ackermann_msgs.msg import AckermannDriveStamped, AckermannDrive
from sensor_msgs.msg import Image, LaserScan, Joy
from cv_bridge import CvBridge, CvBridgeError
device = torch.device('cuda' if torch.cuda.is_available else 'cpu')

__author__ = 'Dhruv Karthik <dhruvkar@seas.upenn.edu>'

class NN_Steer(object):
    """
    Steer the F110 Car using commands generated by a pytorch Neural Network
    """
    def __init__(self, model_name='model'):
        
        self.load_net(model_name=model_name) #updates self.net


        #Setup Subscribers & Publishers
        self.lidar_sub = rospy.Subscriber('/scan', LaserScan, self.lidar_callback)
        self.cam_sub = rospy.Subscriber('/usb_cam/image_raw', Image, self.cam_callback)
        self.steer_sub = rospy.Subscriber('/vesc/low_level/ackermann_cmd_mux/output', AckermannDriveStamped, self.steer_callback)
        self.steer_pub = rospy.Publisher("vesc/high_level/ackermann_cmd_mux/input/nav_0", AckermannDriveStamped, queue_size=1)
        self.env_signal_pub = rospy.Publisher("/env_signal", String, queue_size=10)
        self.env_signal_sub = rospy.Subscriber("/env_signal", String, self.recv_signal)

        #At what interval should we sample to get a steering angle
        self.sample_interval = 4
        self.framecount = 0

        #misc stuff to keep track 
        self.bridge = CvBridge()
        self.dutils = Data_Utils()
        self.funclist = session["online"]["funclist"]
        self.steer_history = [] #history of steers, useful for resets

    def recv_signal(self, data):
        signal_str = data.data
        if 'update_nn' in signal_str:
            self.load_net

    def send_signal(self, signal_str):
        rospy.env_signal_pub.Publish(signal_str)

    def lidar_callback(self, data):
        ranges = data.ranges
        angle_min = data.angle_min
        angle_incr = data.angle_incr
        d2reg= lambda deg_start, deg_end : ranges[int(angle_min + angle_incr * (deg_start * math.pi/180.0)) : int(angle_min + angle_incr * (deg_end* math.pi/180.0))]

        tooclose = lambda r, min_range : min(r) <= min_range

        #ensure that boundaries are met in each region
        r1 = d2reg(0, 45.0)
        r2 = d2reg(45.0, 135.0)
        r3 = d2reg(135.0, 179.0)

        #if not, then reset
        if tooclose(r1, 0.15) or tooclose(r2, 0.3) or tooclose(r3, 0.15):
            self.send_signal('reset')
            self.env_reset()
            self.send_signal('continue')

    def steer_callback(self, data):
        steer_dict = {'angle':data.drive.steering_angle, 'speed':data.drive.speed}
        self.steer_history.append([steer_dict])
    
    def get_drive_msg(self, angle, vel, flip_angle=1.0):
        drive_msg = AckermannDriveStamped()
        drive_msg.header.stamp = rospy.Time.now()
        drive_msg.header.frame_id = "odom" 
        drive_msg.drive.steering_angle = flip_angle * angle
        drive_msg.drive.speed = vel
        return drive_msg

    def env_reset(self):
        backtrack = min(10, len(self.steer_history))
        curr_steer_history = self.steer_history.copy()
        sign = lambda x: (1, -1)[x < 0]

        for i in range(backtrack):
            steer_dict = backtrack[-1 * i]  
            rev_angle = -1.0 * steer_dict["angle"]
            rev_speed = -1.0 * sign(steer_dict["speed"])
            drive_msg = self.get_drive_msg(rev_angle, rev_speed)
            self.steer_pub(drive_msg)

    def cam_callback(self, data):
        if self.framecount % self.sample_interval == 0:
            try:
                cv_img = self.bridge.imgmsg_to_cv2(data, "bgr8")
            except CvBridgeError as e:
                print(e)
            
            ts_img = self.NN_preprocess(cv_img)
            input_dict = {"img":ts_img}
            #use net to get predicted angle
            output_dict = self.net(input_dict)
            ts_angle_pred = output_dict["angle"]
            print(ts_angle_pred.item())

            #Send to car
            angle_pred = ts_angle_pred.item()
            vel = 0
            driv_msg = self.get_drive_msg(angle_pred, vel, flip=-1.0)
            self.steer_pub.publish(drive_msg)

    def NN_preprocess(self, cv_img):
            #basic serverside preprocess
            cv_img = cv2.resize(cv_img, None, fx=0.5, fy=0.5)
            cv_img = cv2.rotate(cv_img, cv2.ROTATE_90_COUNTERCLOCKWISE)

            #external funclist preprocessing
            src_dict = {"img":cv_img}
            new_data_dict = self.dutils.apply_flist(src_dict, self.funclist, w_rosdict=True)
            cv_img = new_data_dict["img"]

            #Dataset preprocessing
            ts_img = torch.from_numpy(cv_img).permute(2, 0, 1).float()
            ts_img = ts_img[None]
            return ts_img.to(device)

    def load_net(self, model_name='model'):
        modelpath = os.path.join(session["online"]["models_dir"], model_name)
        net = NVIDIA_ConvNet()
        if os.path.exists(modelpath):
            net.load_state_dict(torch.load(modelpath))
        net.to(device)
        net.eval()
        self.net = net
        print("LOADED NETWORK")
        print("DEVICE:{device}".format(device=device))
        print("NETWORK:")
        print(net)

if __name__ == "__main__":
    rospy.init_node("nn_steer", anonymous=True)
    nnsteer = NN_Steer()
    rospy.sleep(0.1)
    rospy.spin()
